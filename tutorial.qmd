---
title: "Introduction to Metabolic Modelling"
subtitle: "Centre for Microbiome Research - Queensland University of Technology"
author: "Alexandre Areias Castro"
toc: true
bibliography: bibliography.bib
csl: https://www.zotero.org/styles/taylor-and-francis-national-library-of-medicine
---

***
In this tutorial:

- You will learn several concepts and methods within metabolic modelling, including:
    - Network reconstruction;
    - Single-model simulations and extensions;
    - Community modelling.
- Use different tools and methodologies for each step;
- Give feedback on this tutorial. I intend to publish it soon!


# Reconstruction and model building

In this section, we will cover:

- How a metabolic model originates from a genome;
- The main types of reconstruction;
- What tools to use.

***

According to ChatGPT, metabolic network reconstruction is:

"(...) a process where the complete set of metabolic reactions and pathways
in a microorganism, tissue, or organism are reconstructed and represented
in a computational model based on its genomic data. This model provides a
comprehensive framework for understanding the organism's metabolic network and
can be used to simulate its behavior under various conditions."

This is a fairly accurate answer. Now, let's look at how we can *actually* do this.

## 1 - Introduction

Metabolic reconstructions are achieved through essentially mapping genes,
reactions and metabolites into one cohesive and interconnected network known
as a **Genome-Scale Metabolic Model (GEM)**. In practical terms, it requires us to
obtain as much information from the genomic data so that through it, we can know
which reactions are related to each of the genes present in the genome. The way
we obtain this information is accomplished using 2 main approaches:

- Bottom-up
- Top-down

Bottom-up approaches are the most common and most used reconstruction
methodologies. They are comprised of a mapping of the genes to some sort
of annotation/database that extracts the proteins and reactions they
mediate/catalyze. Afterwards, they connect all the available reactions
and establish a "mock-up" metabolic network (also known as a scaffold)
and afterwards are curated to cover any missing reactions to the pathways.
Generally speaking, they are extremely good for generating models in a
manual/semi-automated way, but the more you automate them, the more the models
tend to lose **quality**. If you want to maintain quality, the ammount of work
needed to curate and fill the gaps exponentially increases. Examples of tools:
[ModelSEED](https://academic.oup.com/nar/article/49/D1/D575/5912569?login=false)
[@seaverModelSEEDBiochemistryDatabase2021], [merlin](https://academic.oup.com/nar/article/50/11/6052/6606174) [@capelaMerlinImprovedFramework2022] and
[gapseq](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-022
95-1) [@zimmermannGapseqInformedPrediction2021] (for gap-filling).

On the other hand, top-down reconstructions use the scaffolds generated
in the first step and then compare them against a universal or complete
model with all the available reactions in every pathway from a database
and then extract the pathways they have. This methodology is much more
efficient for generating large numbers of models without compromising on
quality and needing manual curation, but bad for generating models for
*de novo* genomes. One example of tools that utilize this approach is
[CarveMe](https://pubmed.ncbi.nlm.nih.gov/30192979/) [@machadoFastAutomatedReconstruction2018].

![**Source:** Machado D, Andrejev S, Tramontano M, et al. Fast automated reconstruction of genome-scale metabolic models for microbial species and communities. Nucleic Acids Research. 2018;46(15):7542–7553.](data/images/gky537fig1.jpg)

## 2 - Model Definition

The file type used to represent metabolic networks as GEMs is the Systems
Biology Markup Language (SBML). These are XML files with specific notation and
rules that allow the grouping and connection between **genes**, **reactions**,
**metabolites** and their respective **units**. There are a large number of
conventions and versions constantly being released to constantly make these
models more updated and comprehensive. To see the specifications for each
version see [here](https://sbml.org/documents/specifications/).

Below is the example of a model for the central carbon metabolism of *E. coli*
(called *e_coli_core*). It is fairly small in size and is the most widely used
model for educational purposes.

```{python}
#| echo: false

!cat data/models/e_coli_core.xml

```

## 3 - Testing

We will now test the *E. coli* ED1a model generated by CarveMe generated through the command below. We will start by reading it and then simulating microbial growth using **Flux-Balance Analysis (FBA)**:

```{python}
#| eval: false

!carve --refseq GCF_000026305.1 -o data/models/ecoli_ed1a.xml -g M9 -i M9 -v

``` 

Now let's test the model!


```{python}

from reframed import load_cbmodel

# Reading the model
model = load_cbmodel('data/models/ecoli_ed1a.xml')

# Summary of the model
model.summary()

```

# Simulation

In this section:

- You will learn how to perform flux balance analysis.
- You will use the ReFramed Python library for metabolic modeling. You can check [their online documentation](https://reframed.readthedocs.io/) for more details.

***

## 1- Running the simulation

The most simple thing you can do with a constraint-based model is to run a flux
balance analysis (FBA) simulation. This simulation method uses a stoichiometric
matrix to represent the metabolic network, where each row represents a
metabolite and each column represents a reaction. Afterwards, it calculates the
flow of metabolites in the network by solving a linear program with an objective
function that normally points towards microbial growth or the production of a
specific metabolite [@orthWhatFluxBalance2010].

> **INFO:** The simulation is using the default objective function (biomass maximization) and environmental conditions (aerobic growth in M9 minimal medium with glucose) that came pre-defined in this model.

```{python}

from reframed import FBA

solution = FBA(model)
print(solution)
    
```

```{python}

solution.show_values(pattern="R_EX", sort=True)
    
```

Questions to explore:

- How realistic are these growth values? How can they be more accurate (if possible)?
- Is *E. coli* growing at its maximum growth rate?

## 2 - Visualizing fluxes

Escher is a really nice tool for displaying fluxes in a metabolic map. It makes
your life easier, especially when comparing flux distributions after performing
some perturbations (such as gene deletions or changes in the growth medium).

```{python}

from reframed import fluxes2escher

fluxes2escher(solution.values)

```

## 3 - Environment and growth media

You can change growth conditions either by modifying the flux bounds of the reactions directly in the model or by supplying those constraints as an argument to the FBA simulation method.

Let's observe what happens if we remove oxygen uptake to simulate anaerobic growth:

```{python}

solution2 = FBA(model, constraints={'R_EX_o2_e':0})
print(solution2)
    
```

```{python}

solution2.show_values(pattern="R_EX", sort=True)
    
```

As expected, *E. coli* switched to a fermentation mode, which resulted in the secretion of fermentation products and a decrease in growth rate.

Again, we can see it better by displaying the flux distribution in a metabolic map.

```{python}

fluxes2escher(solution2.values)

```
## 4 - Comparing with experimental data

In order to validade the relevance of the usage of these methods, let's compare them with experimentally measured fluxes.

Gerosa and co-workers[@gerosaPseudotransitionAnalysisIdentifies2015] have measured fluxes in E. coli growing with different carbon sources.

![](data/images/gerosa2015.png)

Let's load the fluxomics data that has been stored as a CSV file...

```{python}

import pandas as pd
fluxomics = pd.read_csv('data/gerosa2015.csv', index_col=0)

fluxomics.sample(5) # print 5 random entries
    
```

We will constrain the model using only the respective uptake rate for each substrate and see how well it predicts the growth rate and all the other fluxes.

Unfortunately, our model only contains 5 of the 8 substrates used in the paper.

```{python}

uptake_reactions = {
    'Glucose': 'R_EX_glc__D_e',
    'Gluconate': 'R_EX_glcn_e',
    'Galactose': 'R_EX_gal_e',
    'Pyruvate': 'R_EX_pyr_e',
    'Glycerol': 'R_EX_glyc_e',
    'Succinate': 'R_EX_succ_e',
    'Acetate': 'R_EX_ac_e',
    'Fructose': 'R_EX_fru_e',
}

growth_rates = {
    'Glucose': 0.65,
    'Gluconate': 0.59,
    'Galactose': 0.18,
    'Pyruvate': 0.39,
    'Glycerol': 0.49,
    'Succinate': 0.51,
    'Acetate': 0.29,
    'Fructose': 0.49,
}
    
```

We need to remove glucose from the pre-defined medium, by setting the lower bound of the exchange reaction to zero:

```{python}

model.reactions.R_EX_glc__D_e.lb = 0
    
```

Now let's run simulations for all the five conditions.

```{python}

simulated = {}
growth_predicted = {}

for condition, rxn_id in uptake_reactions.items():
    uptake_rate = fluxomics.loc[rxn_id, condition]
    solution = FBA(model, constraints={rxn_id: uptake_rate})
    simulated[f'{condition}_sim'] = solution.values
    growth_predicted[condition] = solution.fobj

combined = pd.concat([fluxomics, pd.DataFrame(simulated)], axis=1, join='inner')

pd.DataFrame({'Growth': growth_rates, 'Predicted': growth_predicted})
```

It seems that, in general, the model predicted similar growth rates to those that were measured.

> Why do you think this happened?

Now let's look at the same procedure with the *e_coli_core* model. Before that, we will have to reduce the number of carbon sources from 8 to 5 to accomodate the available exchange reactions in the model.

```{python}

uptake_reactions = {
    'Glucose': 'R_EX_glc__D_e',
    'Pyruvate': 'R_EX_pyr_e',
    'Succinate': 'R_EX_succ_e',
    'Acetate': 'R_EX_ac_e',
    'Fructose': 'R_EX_fru_e',
}

growth_rates = {
    'Glucose': 0.65,
    'Pyruvate': 0.39,
    'Succinate': 0.51,
    'Acetate': 0.29,
    'Fructose': 0.49,
}
    
```

```{python}

# Reading the model
model = load_cbmodel('data/models/e_coli_core.xml')

model.reactions.R_EX_glc__D_e.lb = 0

simulated = {}
growth_predicted = {}

for condition, rxn_id in uptake_reactions.items():
    uptake_rate = fluxomics.loc[rxn_id, condition]
    solution = FBA(model, constraints={rxn_id: uptake_rate})
    simulated[f'{condition}_sim'] = solution.values
    growth_predicted[condition] = solution.fobj

combined = pd.concat([fluxomics, pd.DataFrame(simulated)], axis=1, join='inner')

pd.DataFrame({'Growth': growth_rates, 'Predicted': growth_predicted})
```

Now we observe that overall, the model predicted higher growth rates than what was measured.

> How can we explain the differences? What could be the variables at play here?

One of the limitations of FBA is that it does not predict overflow metabolism, unless we explicitly add additional constraints.

So let's now additionally constrain the acetate secretion rate as well and see if our predictions improve.

```{python}

simulated = {}
growth_predicted = {}

for condition, rxn_id in uptake_reactions.items():
    constraints = {
        rxn_id: fluxomics.loc[rxn_id, condition],
        'R_EX_ac_e': fluxomics.loc['R_EX_ac_e', condition],
    }
    solution = FBA(model, constraints=constraints)
    simulated[f'{condition}_sim'] = solution.values
    growth_predicted[condition] = solution.fobj

combined2 = pd.concat([fluxomics, pd.DataFrame(simulated)], axis=1, join='inner')

pd.DataFrame({'Growth': growth_rates, 'Predicted': growth_predicted})
```

There is some improvement in the prediction of growth rates. But what about the fluxes? How well are they predicted, and does this also improve when we constrain acetate secretion?

The  plots below represent the measured vs predicted fluxes, before and after constraining acetate secretion.

```{python}

import matplotlib.pyplot as plt

fig, axs = plt.subplots(2, 5, figsize=(15, 6))

for i, condition in enumerate(uptake_reactions):
    combined.plot.scatter(condition, f'{condition}_sim', ax=axs[0,i])
    axs[0,i].plot([-20, 20], [-20, 20], 'k--', alpha=0.3)
    
    combined2.plot.scatter(condition, f'{condition}_sim', ax=axs[1,i])
    axs[1,i].plot([-20, 20], [-20, 20], 'k--', alpha=0.3)

fig.tight_layout()
    
```


<!-- ## 5 - Extensions of models -->

<!-- As you might have understood by now, the secret to accurate predictions lies in the constraints applied to the system. That is because by doing so, we reduce the **solution space** to the point where the predicted fluxes are extremely accurate. -->

<!-- ![**Source:** Orth JD, Thiele I, Palsson BØ. What is flux balance analysis? Nature biotechnology. 2010;28(3):245–248.](data/images/solution_space.png) -->

<!-- However, how do we reduce the solution space **and** shift it towards real flux values? -->

<!-- Currently we have 2 main options: -->

<!-- - We comprehensively define the growth media with highly precise fluxes -->
<!-- - We integrate omics data into the model -->

<!-- Defining a really accurate growth media is extremely dificult. First, because converting metabolite concentration into uptake fluxes is next to impossible. Therefore, most advances in this area have been towards extending and enhancing the models with various omics data. -->

<!-- There are currently a few tools that automatically integrate omics (mainly enzymatic/proteomics data) into a model. These processes generate what is commonly known as a **enzyme-constrained Genome-Scale Metabolic Model (ecGEM)**, with some small variances in both the process and the outcome. Some of the main tools and workflows are [ECMpy](https://github.com/tibbdc/ECMpy)[@maoECMpySimplifiedWorkflow2022], [GECKO](https://github.com/SysBioChalmers/GECKO/)[@chenReconstructionSimulationAnalysis2024], MOMENT[@adadiPredictionMicrobialGrowth2012] (sMOMENT->[AutoPACMEN](https://github.com/klamt-lab/autopacmen))[@bekiarisAutomaticConstructionMetabolic2020] and my own published on [GitHub](https://github.com/areias03/tmcom). -->
<!-- The process consists of 5 main stages: -->

<!-- 1. Expansion from a starting metabolic model to an ecModel structure -->
<!-- 2. Integration of enzyme turnover numbers into the ecModel structure -->
<!-- 3. Model tuning (or calibration) -->
<!-- 4. Integration of proteomics data into the ecModel -->
<!-- 5. Simulation and analysis of ecModels -->

<!-- Due to the complexity of the process, and mainly, our own time constraints we will just use a model generated by one of them, in this case the ... methodology -->


# Community Modeling


In this part:

- Build models for artificial communities
- Use the [MEWpy]() library for metabolic modelling. You can also read the documentation [here]().
- Analyze interactions and results from different simulation methods.

***

## 1 - Introduction

Microbial communities are the natural occuring form of micrboes. To that end, if we want accurate predictions of microbial behaviour, it is important to represent them in conditions as close to those obsreved in nature as possible.
To achieve this, we generate community models that include every gene, reaction and metabolite mapped to the each microbe, with a community exchange compartment to enable cross-cross-feeding and interactions, similarly to the observed below. 

![**Source:** Colarusso AV, Goodchild-Michelman I, Rayle M, et al. Computational modeling of metabolism in microbial communities on a genome-scale. Current Opinion in Systems Biology. 2021;26:46–57.](data/images/community_model.jpg)

There are a multitude of tools and libraries that enable us to generate, manipulate and simulate with these models. Some of the most notable include ReFramed, [MEWpy](https://github.com/BioSystemsUM/MEWpy/)[@pereiraMEWpyComputationalStrain2021] and [micom](https://github.com/micom-dev/micom)[@dienerMICOMMetagenomeScaleModeling2020]. For this part of the tutorial, we will use MEWpy. You can check more of the documentation [here](https://mewpy.readthedocs.io/)

## 2 - Setting up

```{python}

import mewpy
mewpy.info()

```

We will create a synthetic microbial consortium with two *E. coli* mutants growing in minimal medium. In one of the mutants we will knockout the glucose transporter and in the other we will knockout the ammonium transporter.

```{python}

from cobra.io import read_sbml_model
from mewpy import get_simulator

wild= read_sbml_model('data/models/e_coli_core.xml.gz')
wildtype = get_simulator(wild)
solution = wildtype.simulate()
print(solution)
solution.find('EX')

```

Now we create our two mutants (`glc_ko` and `nh4_ko`):

```{python}

glc_ko = wildtype.copy()
glc_ko.id = 'glc_ko'
glc_ko.set_reaction_bounds('GLCpts', 0, 0)

```

```{python}

nh4_ko = wildtype.copy()
nh4_ko.id = 'nh4_ko'
nh4_ko.set_reaction_bounds('NH4t', 0, 0)

```

### Comparing models

Community models require that metabolites have the same identifiers across all models. We can verify that by computing the metabolites, reactions and uptakes overlaps between a list models.

```{python}

from mewpy.com import *
mets, rxns, over = jaccard_similarity_matrices([glc_ko, nh4_ko])

```

```{python}

mets

```
```{python}

rxns

```
```{python}

over

```

### Building communities

Let's initiate the `CommunityModel` class to create microbial communities from a list of models of individual species:

```{python}

from mewpy.model import CommunityModel
community1 = CommunityModel([glc_ko, nh4_ko],flavor='cobra')
sim_com = community1.get_community_model()

```

This community model ignores the environmental conditions that were specified in the original models (since these could be very different).

To make our life easier, we will extract the nutrient composition specified in the wild-type model to use later.

```{python}

from mewpy.simulation import Environment
M9 = Environment.from_model(wildtype)
M9

```

## 3 - Simulation using FBA

A very simple way to simulate a microbial community is to merge the individual models into a single model that mimics a "super organism", where each microbe lives inside its own compartment, and run a (conventional) FBA simulation for this super organism.

```{python}

sol_com = sim_com.simulate(constraints=M9)

print(sol_com)
sol_com.find('EX')

```

We can see that the model predicts a growth rate (total biomass per hour) similar to the wild-type, with an efficient consumption of glucose and ammonia that results in respiratory metabolism.

But what is each organism doing, and are both organisms actually growing at the same rate?

```{python}

sol_com.find(pattern='BIOMASS', sort=True, show_nulls=True)

```

Let's print the all non null fluxes by organism:

```{python}

sol_com.find(pattern='_glc_ko', sort=True)

```

```{python}

sol_com.find(pattern='_nh4_ko', sort=True)

```

Actually it seems that only one of the organisms is growing while the other has an active metabolism (it exchanges metabolites with the environment and with the other organism) performing the role of a bioconverter, but none of the flux is used for growth.

> Do you think this would be a stable consortium ?


## 4 - Simulation using SteadyCom

SteadyCom[@chanSteadyComPredictingMicrobial2017] is a recent community simulation method that takes into account the fact that to reach a stable composition the organisms need to grow at the same specific growth rate (1/h), which means that the absolute growth rate (gDW/h) of each organism is proportional to its abundance at steady-state (gDW).

Let's simulate the same community using SteadyCom:

```{python}

steady= SteadyCom(community1, constraints=M9)

```

In this case the solution object shows the overall community growth rate and the relative abundance of each species:

```{python}

print(steady)

```

The `solution` object for community simulations implements a few additional features, such as enumerating all the cross-feeding interactions:

```{python}

steady.cross_feeding(as_df=True).dropna().sort_values('rate', ascending=False)

```

We can plot the fluxes of each mutant in a map to help with interpretation of the results:

```{python}

from mewpy.visualization.escher import build_escher
build_escher(fluxes=steady.internal['glc_ko'])

```

```{python}

build_escher(fluxes=steady.internal['nh4_ko'])

```
## 5 - Explore alternative solutions

Unfortunately, one limitation of SteadyCom, which is exemplified by Chan, et al (2017) in Figure 3 (reproduced below), is the variability in the solution space when the community is not growing at the maximum (theoretical) growth rate.

> Would you expect a synthetic community to grow at its maximum growth rate?

MEWpy implements a variability analysis function for the SteadyCom solution space, let's see what happens if the community is growing at 90% of the theoretical maximum:

```{python}

from mewpy.com import SteadyComVA
variability = SteadyComVA(community1, obj_frac=0.9, constraints=M9)

print('Strain\tMin\tMax')
for strain, (lower, upper) in variability.items():
    print(f'{strain}\t{lower:.1%}\t{upper:.1%}')
    
```

As you can see, there is a really large variability in this solution space. This means that we know in theory the two mutants can cooperate and survive in minimal media, but there is still a lot of uncertainty with regard to how they will achieve a stable consortium.

> How do you think we can reduce this uncertainty?

Firstly, lets set the environment conditions:

```{python}

sim_com.set_environmental_conditions(M9)

```


We may now impose constraints on each organism growth, such as stating that each organism need to grow at least 0.1/h.

```{python}

constraints2={community1.organisms_biomass['nh4_ko']:(0.1,1000), 
             community1.organisms_biomass['glc_ko']:(0.1,1000)}
sol_abun = sim_com.simulate(constraints=constraints2)
sol_abun

```

```{python}

sol_abun.find('BIOMASS')

```

Alternatively, we might choose to impose relative growth rates for each of the organisms, as a proxy of the community composition:


```{python}

community2 = CommunityModel([glc_ko, nh4_ko],
                           add_compartments=True,
                           merge_biomasses=True,
                           flavor='cobra')

```

```{python}

sim_com2 = community2.get_community_model()
sim_com2.set_environmental_conditions(M9)

```

```{python}

sol_rel = sim_com2.simulate()
print(sol_rel)
sol_rel.find('BIOMASS')

```

```{python}


sim_com2.find(community2.biomass)

```

```{python}

community2.set_abundance({'glc_ko':1,'nh4_ko':2.5})
sim_com2.simulate().find('BIOMASS')

```

## 6 - Interaction Analysis (SMETANA)

SMETANA[@zelezniakMetabolicDependenciesDrive2015] implements several algorithms to analyse cross-feeding interactions in microbial communities. Please read the paper for a more detailed explanation.

**SCS (species coupling score):** measures the dependency of one species in the presence of the others to survive

```{python}

sc_score(community1)
    
```

**MUS (metabolite uptake score):** measures how frequently a species needs to uptake a metabolite to survive

```{python}

MUS = mu_score(community1)
MUS

```

```{python}

MUS.glc_ko

```

```{python}

MUS.nh4_ko

```

**MPS (metabolite production score):** measures the ability of a species to produce a metabolite

```{python}

MPS = mp_score(community1,environment=M9)
MPS

```

**MRO (metabolic resource overlap):** calculates how much the species compete for the same metabolites.

```{python}

score, MRO = mro_score(community1,environment=M9)
print(score)
MRO

```

```{python}

MRO.individual_media.glc_ko

```

```{python}

MRO.individual_media.nh4_ko

```

# References

The code here presented is highly inspired and extracted from the ones in:

- [embo_mcd22](https://github.com/cdanielmachado/embo_mcd22/tree/main)
- [MEWpy/examples](https://github.com/BioSystemsUM/MEWpy/tree/master/examples)

::: {#refs}
:::
